'''
Created on Apr 1, 2017

@author: zoya
'''
import os
import pandas
from sklearn.preprocessing import LabelEncoder
import numpy as np
import tensorflow as tf
from tensorflow.contrib import learn


TRAIN_DF = 'train_184.csv'
TEST_DF = 'test_183.csv'

LABEL_COLUMN = "out"

def input_fn(df):
    CATEGORICAL_COLUMNS = ['building_id', 'manager_id', 'listing_id', 'street_address', "display_address", 'display_address_cleaned']
    df[CATEGORICAL_COLUMNS] = df[CATEGORICAL_COLUMNS].fillna('')
    
    CONTINUOUS_COLUMNS = list(set(df.columns.values[1:20]) - set(CATEGORICAL_COLUMNS))
    # Creates a dictionary mapping from each continuous feature column name (k) to
    # the values of that column stored in a constant Tensor.
    continuous_cols = {k: tf.constant(df[k].values)
                     for k in CONTINUOUS_COLUMNS}
    # Creates a dictionary mapping from each categorical feature column name (k)
    # to the values of that column stored in a tf.SparseTensor.
    categorical_cols = {k: tf.SparseTensor(
                                           indices=[[i, 0] for i in range(df[k].size)],
                                           values=df[k].values,
                                           dense_shape=[df[k].size, 1])
                        for k in CATEGORICAL_COLUMNS}
    # Merges the two dictionaries into one.
    feature_cols = continuous_cols
    feature_cols.update(categorical_cols)
    
    # Converts the label column into a constant Tensor.
    label = tf.constant(df[LABEL_COLUMN].values)
    # Returns the feature columns and the label.
    return feature_cols, label

def train_input_fn():
    df_train = pandas.read_csv(TRAIN_DF)[0:49000]
    # uncomment, if out is still low-medium-high
    # labels = {'high':0, 'medium':1, 'low':2}
    # df_train[LABEL_COLUMN] = df_train["out"].apply(lambda x: labels[x])#.astype(int)
    return input_fn(df_train)

def eval_input_fn():
    df_train = pandas.read_csv(TRAIN_DF)[49001:49352]
    # uncomment, if out is still low-medium-high
    # labels = {'high':0, 'medium':1, 'low':2}
    # df_train[LABEL_COLUMN] = df_train["out"].apply(lambda x: labels[x])#.astype(int)
    return input_fn(df_train)

def test_input_fn():
    df_test = pandas.read_csv(TEST_DF)
    df_test[LABEL_COLUMN] = 0
    return input_fn(df_test)


def main():
    # Load datasets.
    # feature_columns, label = train_input_fn()
    # test_set = eval_input_fn()
    
    # Specify that all features have real-value data
    # feature_columns = [tf.contrib.layers.real_valued_column("", dimension=183)]
    
    # feature_columns = [tf.contrib.layers.sparse_column_with_hash_bucket("building_id", hash_bucket_size=1000)]
    
    # building = tf.contrib.layers.sparse_column_with_hash_bucket("building_id", hash_bucket_size=100)
    # manager = tf.contrib.layers.sparse_column_with_hash_bucket("manager_id", hash_bucket_size=100)
    # feature_columns = [tf.contrib.layers.embedding_column(manager, dimension=None), 
    #                   tf.contrib.layers.embedding_column(building, dimension=None)]
    
    feature_columns = [tf.contrib.layers.real_valued_column("", dimension=10)]
    
    # Build 3 layer DNN with 10, 20, 10 units respectively.
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                                hidden_units=[30, 20, 30],
                                                n_classes=3,
                                                model_dir="/tmp/renthop_model2")
    
    # Fit model.
    classifier.fit(input_fn=train_input_fn, steps=2000)
    p = classifier.evaluate(input_fn=eval_input_fn, steps=1)
    print (p)
    
    # predictions = list(classifier.predict(input_fn=eval_input_fn))
    df_train = pandas.read_csv(TRAIN_DF)
    pred = list(classifier.predict(input_fn=lambda: input_fn(df_train[49001:49004])))
    vals = df_train[49001:49004][LABEL_COLUMN]
    
    eval_len = 100
    pred_prob = list(classifier.predict_proba(input_fn=lambda: input_fn(df_train[49001:(49001+eval_len)])))
    vals = list(df_train[49001:(49001+eval_len)][LABEL_COLUMN])
    
    tt = []
    tt.append([0 if vals[i]!=0 else 1 for i in range(0, eval_len)])
    tt.append([0 if vals[i]!=1 else 1 for i in range(0, eval_len)])
    tt.append([0 if vals[i]!=1 else 1 for i in range(0, eval_len)])
    y = np.asarray(tt).T.tolist()
    
    test_pred_prob = classifier.predict_proba(input_fn=test_input_fn)
    result = list()
    for p in test_pred_prob:
        result.append(list(p))

    cross_entropy = tf.reduce_mean(
                               tf.nn.softmax_cross_entropy_with_logits(labels=vals, logits=pred))

    # Evaluate accuracy.
    accuracy_score = classifier.evaluate(input_fn=eval_input_fn,
                                             steps=1)["accuracy"]
        
    print("\nTest Accuracy: {0:f}\n".format(accuracy_score))
        
        # Classify two new flower samples.
    def new_samples():
        return np.array(
            [[6.4, 3.2, 4.5, 1.5],
             [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)
        
    predictions = list(classifier.predict(input_fn=new_samples))
        
    print("New Samples, Class Predictions:    {}\n".format(predictions))
        
if __name__ == "__main__":
    os.chdir('/Users/zoya/projects/datascience/tensorflow/tensorflow/com/zoya/tf/renthop/')
    tf.logging.set_verbosity(tf.logging.INFO)
    main()
