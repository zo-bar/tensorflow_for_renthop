'''
Created on Apr 1, 2017

@author: zoya
'''
import os
import pandas
from sklearn.preprocessing import LabelEncoder
import numpy as np
import tensorflow as tf
from tensorflow.contrib import learn


TRAIN_DF = 'train_184.csv'
TEST_DF = 'test_183.csv'

LABEL_COLUMN = "out"

def input_fn(df):
    CATEGORICAL_COLUMNS = ['building_id', 'manager_id', 'listing_id', 'street_address', "display_address", 'display_address_cleaned']
    df[CATEGORICAL_COLUMNS] = df[CATEGORICAL_COLUMNS].fillna('')
    
    CONTINUOUS_COLUMNS = list(set(df.columns.values[1:20]) - set(CATEGORICAL_COLUMNS))
    # Creates a dictionary mapping from each continuous feature column name (k) to
    # the values of that column stored in a constant Tensor.
    continuous_cols = {k: tf.constant(df[k].values)
                     for k in CONTINUOUS_COLUMNS}
    # Creates a dictionary mapping from each categorical feature column name (k)
    # to the values of that column stored in a tf.SparseTensor.
    categorical_cols = {k: tf.SparseTensor(
                                           indices=[[i, 0] for i in range(df[k].size)],
                                           values=df[k].values,
                                           dense_shape=[df[k].size, 1])
                        for k in CATEGORICAL_COLUMNS}
    # Merges the two dictionaries into one.
    feature_cols = continuous_cols
    feature_cols.update(categorical_cols)
    
    # Converts the label column into a constant Tensor.
    label = tf.constant(df[LABEL_COLUMN].values)
    # Returns the feature columns and the label.
    return feature_cols, label

def train_input_fn():
    df_train = pandas.read_csv(TRAIN_DF)
    # uncomment, if out is still low-medium-high
    #labels = {'high':0, 'medium':1, 'low':2}
    #df_train[LABEL_COLUMN] = df_train["out"].apply(lambda x: labels[x])#.astype(int)
    return input_fn(df_train)

def eval_input_fn():
    df_test = pandas.read_csv(TEST_DF)
    df_test[LABEL_COLUMN] = 0
    return input_fn(df_test)


def main():
    # Load datasets.
    #feature_columns, label = train_input_fn()
    #test_set = eval_input_fn()
    
    # Specify that all features have real-value data
    #feature_columns = [tf.contrib.layers.real_valued_column("", dimension=183)]
    
    #feature_columns = [tf.contrib.layers.sparse_column_with_hash_bucket("building_id", hash_bucket_size=1000)]
    building = tf.contrib.layers.sparse_column_with_hash_bucket("building_id", hash_bucket_size=100)

    feature_columns = [tf.contrib.layers.embedding_column(building, dimension=8)]
    
    # Build 3 layer DNN with 10, 20, 10 units respectively.
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                                hidden_units=[10, 20, 10],
                                                n_classes=3,
                                                model_dir="/tmp/renthop_model")
    
    # Fit model.
    classifier.fit(input_fn=train_input_fn, steps=2000)
        
    # Evaluate accuracy.
    accuracy_score = classifier.evaluate(input_fn=eval_input_fn,
                                             steps=1)["accuracy"]
        
    print("\nTest Accuracy: {0:f}\n".format(accuracy_score))
        
        # Classify two new flower samples.
    def new_samples():
        return np.array(
            [[6.4, 3.2, 4.5, 1.5],
             [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)
        
    predictions = list(classifier.predict(input_fn=new_samples))
        
    print("New Samples, Class Predictions:    {}\n".format(predictions))
        
if __name__ == "__main__":
    os.chdir('/Users/zoya/projects/datascience/tensorflow/tensorflow/com/zoya/tf/renthop/')
    main()
