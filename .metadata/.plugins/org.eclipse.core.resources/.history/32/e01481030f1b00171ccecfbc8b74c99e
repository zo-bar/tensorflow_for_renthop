'''
Created on Apr 5, 2017

@author: zoya
'''
import os
import pandas
import tensorflow as tf
import pandas as pd
import tempfile

TRAIN_DF = 'train_184.csv'
TEST_DF = 'test_183.csv'

LABEL_COLUMN = "out"
CATEGORICAL_COLUMNS = ['building_id', 'manager_id', 'street_address', 
                       'display_address', 'display_address_cleaned']
CONTINUOUS_COLUMNS = ['long_lat_185', 'walk', 'ok', 'long_lat_339', 
                      'long_lat_126', 'renovated', 'super', 'latitude', 
                      'level', 'price', 'internet', 'mean_bed_price', 'pets', 
                      'feature_count', 'exclusive', 'long_lat_336', 
                      'public_laundry', 'luxury', 'long_lat_362', 'central', 
                      'room_price_desc', 'long_lat_52', 'access', 'newly', 
                      'long_lat_333', 'long_lat_317', 'loft', 'long_lat_11', 
                      'long_lat_107', 'granite', 'space', 'old', 'long_lat_6', 
                      'long_lat_373', 'long_lat_105', 'patio', 'room_diff', 
                      'anticipation', 'actual', 'weekday', 'fee', 'price_ratio', 
                      'long_lat_300', 'trust', 'long_lat_54', 'light', 'lounge', 
                      'allowed', 'surprise', 'reduced', 'disgust', 'day', 'garage', 
                      'long_lat_225', 'room_sum_desc', 'long_lat_165', 'bed_price_desc', 
                      'private_laundry', 'swimming', 'long_lat_16', 'long_lat_89', 
                      'deck', 'long_lat_324', 'long_lat_12', 'long_lat_35', 'pre', 
                      'construction', 'long_lat_338', 'outdoor', 'private_outdoor', 
                      'residents', 'photo_count', 'long_lat_355', 'balcony', 'storage', 
                      'negative', 'hour', 'live', 'pool', 'public_outdoor', 'bedrooms', 
                      'bed_ratio_desc', 'bedrooms_desc', 'view', 'simplex', 'room_sum',
                      'long_lat_332', 'bathrooms', 'common', 'steel', 'long_lat_302', 
                      'long_lat_20', 'manager_count', 'room_diff_desc', 'private', 
                      'long_lat_330', 'roof', 'terrace', 'long_lat_335', 'gym']
                      
                      

rest=[ 
                      'long_lat_345', 'children', 'long_lat_283', 'listing_id', 
                      'positive', 'long_lat_106', 'floors', 'elevator', 'playroom',
                      
                      'long_lat_372', 'unit', 'long_lat_320', 'bike', 'long_lat_24', 
                      'garden', 'fear', 'speed', 'month', 'cats', 'long_lat_71', 
                      'dining', 'sadness', 'anger', 'long_lat_245', 'long_lat_19', 
                      'approval', 'joy', 'dishwasher', 'location', 'hardwood', 
                       
                      'long_lat_21', 'doorman', 'long_lat_303', 'long_lat_145', 
                      'high_ceilings', 'war', 'long_lat_67', 'long_lat_68', 'site', 
                      'long_lat_359', 'new', 'washer', 'green', 'long_lat_304', 
                      'furnished', 'longitude', 'bed_price', 'wheelchair', 'long_lat_14', 
                      'fitness', 'bed_ratio', 'long_lat_357', 'kitchen', 'high', 
                      'appliances', 'long_lat_13', 'long_lat_205', 'building', 
                      'long_lat_370', 'long_lat_127', 'prewar', 'concierge', 
                      'long_lat_356', 'long_lat_264', 'dogs', 'room_price', 'ceiling', 
                      'long_lat_281', 'service', 'parking', 'multi', 'short_term', 
                      'long_lat_349', 'laundry', 'closet', 'description_len', 'long_lat_2', 
                      'fireplace']


def input_fn(df):
    df[CATEGORICAL_COLUMNS] = df[CATEGORICAL_COLUMNS].fillna('')
    df[CONTINUOUS_COLUMNS] = df[CONTINUOUS_COLUMNS].fillna(0)
    # print("Categorical columns: " + str(CATEGORICAL_COLUMNS))
    # print("Continuous columns: " + str(CONTINUOUS_COLUMNS))
    #     
    # Creates a dictionary mapping from each continuous feature column name (k) to
    # the values of that column stored in a constant Tensor.
    continuous_cols = {k: tf.constant(df[k].values, shape=[df[k].size, 1])
                     for k in CONTINUOUS_COLUMNS}
    # Creates a dictionary mapping from each categorical feature column name (k)
    # to the values of that column stored in a tf.SparseTensor.
    categorical_cols = {k: tf.SparseTensor(
                                           indices=[[i, 0] for i in range(df[k].size)],
                                           values=df[k].values,
                                           dense_shape=[df[k].size, 1])
                        for k in CATEGORICAL_COLUMNS}
    
    # Merges the two dictionaries into one.
    feature_cols = continuous_cols
    feature_cols.update(categorical_cols)
    
    # Converts the label column into a constant Tensor.
    label = tf.constant(df[LABEL_COLUMN].values)
    # Returns the feature columns and the label.
    return feature_cols, label

def main():
    df_train = pandas.read_csv(TRAIN_DF)
    df_test = pandas.read_csv(TEST_DF)
    df_test[LABEL_COLUMN] = 0
    
    global CONTINUOUS_COLUMNS
    col_names = list(df_train.columns.values)
    col_names.remove('row')
    col_names.remove('out')
    #CONTINUOUS_COLUMNS = list(set(col_names) - set(CATEGORICAL_COLUMNS))
    
    feature_columns = list()
    for c in CONTINUOUS_COLUMNS:
        feature_columns.append(tf.contrib.layers.real_valued_column(c))
    
    for col in CATEGORICAL_COLUMNS:
        col_tensor = tf.contrib.layers.sparse_column_with_hash_bucket(col, hash_bucket_size=100)
        feature_columns.append(col_tensor)
    
    # Build 3 layer DNN with 10, 20, 10 units respectively.
#     classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
#                                                 hidden_units=[5, 10, 5],
#                                                 n_classes=3,
#                                                 model_dir="/tmp/renthop_model_second2")
    
    model_dir = tempfile.mkdtemp()
    classifier  = tf.contrib.learn.LinearClassifier(feature_columns=feature_columns, 
                                                    model_dir=model_dir,
                                                    n_classes=3)
    
    # Fit model.
    classifier.fit(input_fn=lambda: input_fn(df_train), steps=1000)
    
    #test_pred_prob = classifier.predict_proba(input_fn=lambda: input_fn(df_test))
    #out_df = pd.DataFrame([list(p) for p in test_pred_prob])
    #out_df.columns = ["low", "medium", "high"]
    #out_df["listing_id"] = df_test.listing_id.values
    #out_df.to_csv("second_nn1.csv", index=False)

if __name__ == "__main__":
    os.chdir('/Users/zoya/projects/datascience/tensorflow/tensorflow/com/zoya/tf/renthop/')
    tf.logging.set_verbosity(tf.logging.INFO)
    main()
