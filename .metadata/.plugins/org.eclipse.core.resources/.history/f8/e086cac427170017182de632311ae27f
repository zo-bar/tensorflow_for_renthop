'''
Created on Apr 1, 2017

@author: zoya
'''
import os
import pandas
from sklearn.preprocessing import LabelEncoder
import numpy as np
import tensorflow as tf
from tensorflow.contrib import learn


TRAIN_DF = 'train_184.csv'
TEST_DF = 'test_184.csv'

TF_TRAIN_DF = 'tf_train_184.csv'
TF_TEST_DF = 'tf_test_184.csv'

LABEL_COLUMN = "label"

def input_fn(df):
    CATEGORICAL_COLUMNS = ['building_id', 'manager_id', 'listing_id', 'street_address', "display_address", 'display_address_cleaned']
    
    CONTINUOUS_COLUMNS = list(set(df.columns.values[1:20]) - set(CATEGORICAL_COLUMNS))
    # Creates a dictionary mapping from each continuous feature column name (k) to
    # the values of that column stored in a constant Tensor.
    continuous_cols = {k: tf.constant(df[k].values)
                     for k in CONTINUOUS_COLUMNS}
    # Creates a dictionary mapping from each categorical feature column name (k)
    # to the values of that column stored in a tf.SparseTensor.
    categorical_cols = {k: tf.SparseTensor(
                                           indices=[[i, 0] for i in range(df[k].size)],
                                           values=df[k].values,
                                           shape=[df[k].size, 1])
                        for k in CATEGORICAL_COLUMNS}
    # Merges the two dictionaries into one.
    feature_cols = dict(continuous_cols.items() + categorical_cols.items())
    # Converts the label column into a constant Tensor.
    label = tf.constant(df[LABEL_COLUMN].values)
    # Returns the feature columns and the label.
    return feature_cols, label

def train_input_fn():
    df_train = pandas.read_csv(TRAIN_DF)
    df_train[LABEL_COLUMN] = (df_train["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)
    return input_fn(df_train)

def eval_input_fn():
    df_test = pandas.read_csv(TEST_DF)
    df_test[LABEL_COLUMN] = (df_test["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)
    return input_fn(df_test)


def main():
    # Load datasets.
    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
        filename=TF_TRAIN_DF,
        target_dtype=np.int,
        features_dtype=np.float32)
    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
        filename='test_183.csv',
        target_dtype=np.int,
        features_dtype=np.float32)
    
    # Specify that all features have real-value data
    feature_columns = [tf.contrib.layers.real_valued_column("", dimension=183)]
    
    # Build 3 layer DNN with 10, 20, 10 units respectively.
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                                hidden_units=[10, 20, 10],
                                                n_classes=3,
                                                model_dir="/tmp/renthop_model")
    # Define the training inputs
    def get_train_inputs():
        x = tf.constant(training_set.data)
        y = tf.constant(training_set.target)
    
        return x, y
    
    # Fit model.
    classifier.fit(input_fn=get_train_inputs, steps=2000)
    
    # Define the test inputs
    def get_test_inputs():
        x = tf.constant(test_set.data)
        y = tf.constant(test_set.target)
        
        return x, y
        
    # Evaluate accuracy.
    accuracy_score = classifier.evaluate(input_fn=get_test_inputs,
                                             steps=1)["accuracy"]
        
    print("\nTest Accuracy: {0:f}\n".format(accuracy_score))
        
        # Classify two new flower samples.
    def new_samples():
        return np.array(
            [[6.4, 3.2, 4.5, 1.5],
             [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)
        
    predictions = list(classifier.predict(input_fn=new_samples))
        
    print("New Samples, Class Predictions:    {}\n".format(predictions))
        
if __name__ == "__main__":
    os.chdir('/Users/zoya/projects/datascience/tensorflow/tensorflow/com/zoya/tf/renthop/')
    clean_df()
    main()
